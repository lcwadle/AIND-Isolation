
(aind) C:\Users\LC\GitHub\AIND-Isolation>python tournament.py

This script evaluates the performance of the custom_score evaluation
function against a baseline agent using alpha-beta search and iterative
deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use
ID and alpha-beta search with the custom_score functions defined in
game_agent.py.

                        *************************
                             Playing Matches
                        *************************

 Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3
                        Won | Lost   Won | Lost   Won | Lost   Won | Lost
    1       Random      10  |   0    10  |   0    10  |   0    10  |   0
    2       MM_Open      9  |   1     9  |   1     9  |   1     9  |   1
    3      MM_Center    10  |   0     9  |   1    10  |   0    10  |   0
    4     MM_Improved    6  |   4     8  |   2     8  |   2     9  |   1
    5       AB_Open      5  |   5     7  |   3     7  |   3     7  |   3
    6      AB_Center     5  |   5     6  |   4     6  |   4     6  |   4
    7     AB_Improved    6  |   4     4  |   6     4  |   6     6  |   4
--------------------------------------------------------------------------
           Win Rate:      72.9%        75.7%        77.1%        81.4%

Your agents forfeited 106.0 games while there were still legal moves available to play.


(aind) C:\Users\LC\GitHub\AIND-Isolation>